Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark Web UI available at http://mac.lan:4040
Spark master: local[*], Application Id: local-1741581488354
== Parsed Logical Plan ==
'GlobalLimit 100
+- 'LocalLimit 100
   +- 'Sort ['s_store_name ASC NULLS FIRST, 's_company_id ASC NULLS FIRST, 's_street_number ASC NULLS FIRST, 's_street_name ASC NULLS FIRST, 's_street_type ASC NULLS FIRST, 's_suite_number ASC NULLS FIRST, 's_city ASC NULLS FIRST, 's_county ASC NULLS FIRST, 's_state ASC NULLS FIRST, 's_zip ASC NULLS FIRST], true
      +- 'Aggregate ['s_store_name, 's_company_id, 's_street_number, 's_street_name, 's_street_type, 's_suite_number, 's_city, 's_county, 's_state, 's_zip], ['s_store_name, 's_company_id, 's_street_number, 's_street_name, 's_street_type, 's_suite_number, 's_city, 's_county, 's_state, 's_zip, 'sum(CASE WHEN (('sr_returned_date_sk - 'ss_sold_date_sk) <= 30) THEN 1 ELSE 0 END) AS 30_days#0, 'sum(CASE WHEN ((('sr_returned_date_sk - 'ss_sold_date_sk) > 30) AND (('sr_returned_date_sk - 'ss_sold_date_sk) <= 60)) THEN 1 ELSE 0 END) AS 31_60_days#1, 'sum(CASE WHEN ((('sr_returned_date_sk - 'ss_sold_date_sk) > 60) AND (('sr_returned_date_sk - 'ss_sold_date_sk) <= 90)) THEN 1 ELSE 0 END) AS 61_90_days#2, 'sum(CASE WHEN ((('sr_returned_date_sk - 'ss_sold_date_sk) > 90) AND (('sr_returned_date_sk - 'ss_sold_date_sk) <= 120)) THEN 1 ELSE 0 END) AS 91_120_days#3, 'sum(CASE WHEN (('sr_returned_date_sk - 'ss_sold_date_sk) > 120) THEN 1 ELSE 0 END) AS above120_days#4]
         +- 'Filter (((('d2.d_year = 2001) AND ('d2.d_moy = 8)) AND (('ss_ticket_number = 'sr_ticket_number) AND ('ss_item_sk = 'sr_item_sk))) AND ((('ss_sold_date_sk = 'd1.d_date_sk) AND ('sr_returned_date_sk = 'd2.d_date_sk)) AND (('ss_customer_sk = 'sr_customer_sk) AND ('ss_store_sk = 's_store_sk))))
            +- 'Join Inner
               :- 'Join Inner
               :  :- 'Join Inner
               :  :  :- 'Join Inner
               :  :  :  :- 'UnresolvedRelation [store_sales], [], false
               :  :  :  +- 'UnresolvedRelation [store_returns], [], false
               :  :  +- 'UnresolvedRelation [store], [], false
               :  +- 'SubqueryAlias d1
               :     +- 'UnresolvedRelation [date_dim], [], false
               +- 'SubqueryAlias d2
                  +- 'UnresolvedRelation [date_dim], [], false

== Analyzed Logical Plan ==
s_store_name: string, s_company_id: int, s_street_number: string, s_street_name: string, s_street_type: string, s_suite_number: string, s_city: string, s_county: string, s_state: string, s_zip: string, 30_days: bigint, 31_60_days: bigint, 61_90_days: bigint, 91_120_days: bigint, above120_days: bigint
GlobalLimit 100
+- LocalLimit 100
   +- Sort [s_store_name#58 ASC NULLS FIRST, s_company_id#69 ASC NULLS FIRST, s_street_number#71 ASC NULLS FIRST, s_street_name#72 ASC NULLS FIRST, s_street_type#73 ASC NULLS FIRST, s_suite_number#74 ASC NULLS FIRST, s_city#75 ASC NULLS FIRST, s_county#76 ASC NULLS FIRST, s_state#77 ASC NULLS FIRST, s_zip#78 ASC NULLS FIRST], true
      +- Aggregate [s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78], [s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78, sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 30) THEN 1 ELSE 0 END) AS 30_days#0L, sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 30) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 60)) THEN 1 ELSE 0 END) AS 31_60_days#1L, sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 60) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 90)) THEN 1 ELSE 0 END) AS 61_90_days#2L, sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 90) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 120)) THEN 1 ELSE 0 END) AS 91_120_days#3L, sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 120) THEN 1 ELSE 0 END) AS above120_days#4L]
         +- Filter ((((d_year#116 = 2001) AND (d_moy#118 = 8)) AND ((ss_ticket_number#19 = sr_ticket_number#42) AND (ss_item_sk#12 = sr_item_sk#35))) AND (((ss_sold_date_sk#10 = d_date_sk#82) AND (sr_returned_date_sk#33 = d_date_sk#110)) AND ((ss_customer_sk#13 = sr_customer_sk#36) AND (ss_store_sk#17 = s_store_sk#53))))
            +- Join Inner
               :- Join Inner
               :  :- Join Inner
               :  :  :- Join Inner
               :  :  :  :- SubqueryAlias spark_catalog.tpcds.store_sales
               :  :  :  :  +- Relation spark_catalog.tpcds.store_sales[ss_sold_date_sk#10,ss_sold_time_sk#11,ss_item_sk#12,ss_customer_sk#13,ss_cdemo_sk#14,ss_hdemo_sk#15,ss_addr_sk#16,ss_store_sk#17,ss_promo_sk#18,ss_ticket_number#19,ss_quantity#20,ss_wholesale_cost#21,ss_list_price#22,ss_sales_price#23,ss_ext_discount_amt#24,ss_ext_sales_price#25,ss_ext_wholesale_cost#26,ss_ext_list_price#27,ss_ext_tax#28,ss_coupon_amt#29,ss_net_paid#30,ss_net_paid_inc_tax#31,ss_net_profit#32] parquet
               :  :  :  +- SubqueryAlias spark_catalog.tpcds.store_returns
               :  :  :     +- Relation spark_catalog.tpcds.store_returns[sr_returned_date_sk#33,sr_return_time_sk#34,sr_item_sk#35,sr_customer_sk#36,sr_cdemo_sk#37,sr_hdemo_sk#38,sr_addr_sk#39,sr_store_sk#40,sr_reason_sk#41,sr_ticket_number#42,sr_return_quantity#43,sr_return_amt#44,sr_return_tax#45,sr_return_amt_inc_tax#46,sr_fee#47,sr_return_ship_cost#48,sr_refunded_cash#49,sr_reversed_charge#50,sr_store_credit#51,sr_net_loss#52] parquet
               :  :  +- SubqueryAlias spark_catalog.tpcds.store
               :  :     +- Relation spark_catalog.tpcds.store[s_store_sk#53,s_store_id#54,s_rec_start_date#55,s_rec_end_date#56,s_closed_date_sk#57,s_store_name#58,s_number_employees#59,s_floor_space#60,s_hours#61,s_manager#62,s_market_id#63,s_geography_class#64,s_market_desc#65,s_market_manager#66,s_division_id#67,s_division_name#68,s_company_id#69,s_company_name#70,s_street_number#71,s_street_name#72,s_street_type#73,s_suite_number#74,s_city#75,s_county#76,... 5 more fields] parquet
               :  +- SubqueryAlias d1
               :     +- SubqueryAlias spark_catalog.tpcds.date_dim
               :        +- Relation spark_catalog.tpcds.date_dim[d_date_sk#82,d_date_id#83,d_date#84,d_month_seq#85,d_week_seq#86,d_quarter_seq#87,d_year#88,d_dow#89,d_moy#90,d_dom#91,d_qoy#92,d_fy_year#93,d_fy_quarter_seq#94,d_fy_week_seq#95,d_day_name#96,d_quarter_name#97,d_holiday#98,d_weekend#99,d_following_holiday#100,d_first_dom#101,d_last_dom#102,d_same_day_ly#103,d_same_day_lq#104,d_current_day#105,... 4 more fields] parquet
               +- SubqueryAlias d2
                  +- SubqueryAlias spark_catalog.tpcds.date_dim
                     +- Relation spark_catalog.tpcds.date_dim[d_date_sk#110,d_date_id#111,d_date#112,d_month_seq#113,d_week_seq#114,d_quarter_seq#115,d_year#116,d_dow#117,d_moy#118,d_dom#119,d_qoy#120,d_fy_year#121,d_fy_quarter_seq#122,d_fy_week_seq#123,d_day_name#124,d_quarter_name#125,d_holiday#126,d_weekend#127,d_following_holiday#128,d_first_dom#129,d_last_dom#130,d_same_day_ly#131,d_same_day_lq#132,d_current_day#133,... 4 more fields] parquet

== Optimized Logical Plan ==
GlobalLimit 100
+- LocalLimit 100
   +- Sort [s_store_name#58 ASC NULLS FIRST, s_company_id#69 ASC NULLS FIRST, s_street_number#71 ASC NULLS FIRST, s_street_name#72 ASC NULLS FIRST, s_street_type#73 ASC NULLS FIRST, s_suite_number#74 ASC NULLS FIRST, s_city#75 ASC NULLS FIRST, s_county#76 ASC NULLS FIRST, s_state#77 ASC NULLS FIRST, s_zip#78 ASC NULLS FIRST], true
      +- Aggregate [s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78], [s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78, sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 30) THEN 1 ELSE 0 END) AS 30_days#0L, sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 30) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 60)) THEN 1 ELSE 0 END) AS 31_60_days#1L, sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 60) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 90)) THEN 1 ELSE 0 END) AS 61_90_days#2L, sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 90) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 120)) THEN 1 ELSE 0 END) AS 91_120_days#3L, sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 120) THEN 1 ELSE 0 END) AS above120_days#4L]
         +- Project [ss_sold_date_sk#10, sr_returned_date_sk#33, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
            +- Join Inner, (sr_returned_date_sk#33 = d_date_sk#110)
               :- Project [ss_sold_date_sk#10, sr_returned_date_sk#33, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
               :  +- Join Inner, (ss_sold_date_sk#10 = d_date_sk#82)
               :     :- Project [ss_sold_date_sk#10, sr_returned_date_sk#33, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
               :     :  +- Join Inner, (ss_store_sk#17 = s_store_sk#53)
               :     :     :- Project [ss_sold_date_sk#10, ss_store_sk#17, sr_returned_date_sk#33]
               :     :     :  +- Join Inner, (((ss_ticket_number#19 = sr_ticket_number#42) AND (ss_item_sk#12 = sr_item_sk#35)) AND (ss_customer_sk#13 = sr_customer_sk#36))
               :     :     :     :- Project [ss_sold_date_sk#10, ss_item_sk#12, ss_customer_sk#13, ss_store_sk#17, ss_ticket_number#19]
               :     :     :     :  +- Filter ((((isnotnull(ss_ticket_number#19) AND isnotnull(ss_item_sk#12)) AND isnotnull(ss_customer_sk#13)) AND isnotnull(ss_store_sk#17)) AND isnotnull(ss_sold_date_sk#10))
               :     :     :     :     +- Relation spark_catalog.tpcds.store_sales[ss_sold_date_sk#10,ss_sold_time_sk#11,ss_item_sk#12,ss_customer_sk#13,ss_cdemo_sk#14,ss_hdemo_sk#15,ss_addr_sk#16,ss_store_sk#17,ss_promo_sk#18,ss_ticket_number#19,ss_quantity#20,ss_wholesale_cost#21,ss_list_price#22,ss_sales_price#23,ss_ext_discount_amt#24,ss_ext_sales_price#25,ss_ext_wholesale_cost#26,ss_ext_list_price#27,ss_ext_tax#28,ss_coupon_amt#29,ss_net_paid#30,ss_net_paid_inc_tax#31,ss_net_profit#32] parquet
               :     :     :     +- Project [sr_returned_date_sk#33, sr_item_sk#35, sr_customer_sk#36, sr_ticket_number#42]
               :     :     :        +- Filter (((isnotnull(sr_ticket_number#42) AND isnotnull(sr_item_sk#35)) AND isnotnull(sr_customer_sk#36)) AND isnotnull(sr_returned_date_sk#33))
               :     :     :           +- Relation spark_catalog.tpcds.store_returns[sr_returned_date_sk#33,sr_return_time_sk#34,sr_item_sk#35,sr_customer_sk#36,sr_cdemo_sk#37,sr_hdemo_sk#38,sr_addr_sk#39,sr_store_sk#40,sr_reason_sk#41,sr_ticket_number#42,sr_return_quantity#43,sr_return_amt#44,sr_return_tax#45,sr_return_amt_inc_tax#46,sr_fee#47,sr_return_ship_cost#48,sr_refunded_cash#49,sr_reversed_charge#50,sr_store_credit#51,sr_net_loss#52] parquet
               :     :     +- Project [s_store_sk#53, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
               :     :        +- Filter isnotnull(s_store_sk#53)
               :     :           +- Relation spark_catalog.tpcds.store[s_store_sk#53,s_store_id#54,s_rec_start_date#55,s_rec_end_date#56,s_closed_date_sk#57,s_store_name#58,s_number_employees#59,s_floor_space#60,s_hours#61,s_manager#62,s_market_id#63,s_geography_class#64,s_market_desc#65,s_market_manager#66,s_division_id#67,s_division_name#68,s_company_id#69,s_company_name#70,s_street_number#71,s_street_name#72,s_street_type#73,s_suite_number#74,s_city#75,s_county#76,... 5 more fields] parquet
               :     +- Project [d_date_sk#82]
               :        +- Filter isnotnull(d_date_sk#82)
               :           +- Relation spark_catalog.tpcds.date_dim[d_date_sk#82,d_date_id#83,d_date#84,d_month_seq#85,d_week_seq#86,d_quarter_seq#87,d_year#88,d_dow#89,d_moy#90,d_dom#91,d_qoy#92,d_fy_year#93,d_fy_quarter_seq#94,d_fy_week_seq#95,d_day_name#96,d_quarter_name#97,d_holiday#98,d_weekend#99,d_following_holiday#100,d_first_dom#101,d_last_dom#102,d_same_day_ly#103,d_same_day_lq#104,d_current_day#105,... 4 more fields] parquet
               +- Project [d_date_sk#110]
                  +- Filter (((isnotnull(d_year#116) AND isnotnull(d_moy#118)) AND ((d_year#116 = 2001) AND (d_moy#118 = 8))) AND isnotnull(d_date_sk#110))
                     +- Relation spark_catalog.tpcds.date_dim[d_date_sk#110,d_date_id#111,d_date#112,d_month_seq#113,d_week_seq#114,d_quarter_seq#115,d_year#116,d_dow#117,d_moy#118,d_dom#119,d_qoy#120,d_fy_year#121,d_fy_quarter_seq#122,d_fy_week_seq#123,d_day_name#124,d_quarter_name#125,d_holiday#126,d_weekend#127,d_following_holiday#128,d_first_dom#129,d_last_dom#130,d_same_day_ly#131,d_same_day_lq#132,d_current_day#133,... 4 more fields] parquet

== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[s_store_name#58 ASC NULLS FIRST,s_company_id#69 ASC NULLS FIRST,s_street_number#71 ASC NULLS FIRST,s_street_name#72 ASC NULLS FIRST,s_street_type#73 ASC NULLS FIRST,s_suite_number#74 ASC NULLS FIRST,s_city#75 ASC NULLS FIRST,s_county#76 ASC NULLS FIRST,s_state#77 ASC NULLS FIRST,s_zip#78 ASC NULLS FIRST], output=[s_store_name#58,s_company_id#69,s_street_number#71,s_street_name#72,s_street_type#73,s_suite_number#74,s_city#75,s_county#76,s_state#77,s_zip#78,30_days#0L,31_60_days#1L,61_90_days#2L,91_120_days#3L,above120_days#4L])
   +- HashAggregate(keys=[s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78], functions=[sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 30) THEN 1 ELSE 0 END), sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 30) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 60)) THEN 1 ELSE 0 END), sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 60) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 90)) THEN 1 ELSE 0 END), sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 90) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 120)) THEN 1 ELSE 0 END), sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 120) THEN 1 ELSE 0 END)], output=[s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78, 30_days#0L, 31_60_days#1L, 61_90_days#2L, 91_120_days#3L, above120_days#4L])
      +- Exchange hashpartitioning(s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78, 200), ENSURE_REQUIREMENTS, [plan_id=116]
         +- HashAggregate(keys=[s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78], functions=[partial_sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 30) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 30) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 60)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 60) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 90)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 90) AND ((sr_returned_date_sk#33 - ss_sold_date_sk#10) <= 120)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN ((sr_returned_date_sk#33 - ss_sold_date_sk#10) > 120) THEN 1 ELSE 0 END)], output=[s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78, sum#153L, sum#154L, sum#155L, sum#156L, sum#157L])
            +- Project [ss_sold_date_sk#10, sr_returned_date_sk#33, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
               +- BroadcastHashJoin [sr_returned_date_sk#33], [d_date_sk#110], Inner, BuildRight, false
                  :- Project [ss_sold_date_sk#10, sr_returned_date_sk#33, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
                  :  +- BroadcastHashJoin [ss_sold_date_sk#10], [d_date_sk#82], Inner, BuildRight, false
                  :     :- Project [ss_sold_date_sk#10, sr_returned_date_sk#33, s_store_name#58, s_company_id#69, s_street_number#71, s_street_name#72, s_street_type#73, s_suite_number#74, s_city#75, s_county#76, s_state#77, s_zip#78]
                  :     :  +- BroadcastHashJoin [ss_store_sk#17], [s_store_sk#53], Inner, BuildRight, false
                  :     :     :- Project [ss_sold_date_sk#10, ss_store_sk#17, sr_returned_date_sk#33]
                  :     :     :  +- BroadcastHashJoin [ss_ticket_number#19, ss_item_sk#12, ss_customer_sk#13], [sr_ticket_number#42, sr_item_sk#35, sr_customer_sk#36], Inner, BuildRight, false
                  :     :     :     :- Filter ((((isnotnull(ss_ticket_number#19) AND isnotnull(ss_item_sk#12)) AND isnotnull(ss_customer_sk#13)) AND isnotnull(ss_store_sk#17)) AND isnotnull(ss_sold_date_sk#10))
                  :     :     :     :  +- FileScan parquet spark_catalog.tpcds.store_sales[ss_sold_date_sk#10,ss_item_sk#12,ss_customer_sk#13,ss_store_sk#17,ss_ticket_number#19] Batched: true, DataFilters: [isnotnull(ss_ticket_number#19), isnotnull(ss_item_sk#12), isnotnull(ss_customer_sk#13), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/angela/Desktop/spark-3.5.5-bin-hadoop3/spark-warehouse/tpc..., PartitionFilters: [], PushedFilters: [IsNotNull(ss_ticket_number), IsNotNull(ss_item_sk), IsNotNull(ss_customer_sk), IsNotNull(ss_stor..., ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_customer_sk:int,ss_store_sk:int,ss_ticket_number:int>
                  :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[3, int, false], input[1, int, false], input[2, int, false]),false), [plan_id=99]
                  :     :     :        +- Filter (((isnotnull(sr_ticket_number#42) AND isnotnull(sr_item_sk#35)) AND isnotnull(sr_customer_sk#36)) AND isnotnull(sr_returned_date_sk#33))
                  :     :     :           +- FileScan parquet spark_catalog.tpcds.store_returns[sr_returned_date_sk#33,sr_item_sk#35,sr_customer_sk#36,sr_ticket_number#42] Batched: true, DataFilters: [isnotnull(sr_ticket_number#42), isnotnull(sr_item_sk#35), isnotnull(sr_customer_sk#36), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/angela/Desktop/spark-3.5.5-bin-hadoop3/spark-warehouse/tpc..., PartitionFilters: [], PushedFilters: [IsNotNull(sr_ticket_number), IsNotNull(sr_item_sk), IsNotNull(sr_customer_sk), IsNotNull(sr_retu..., ReadSchema: struct<sr_returned_date_sk:int,sr_item_sk:int,sr_customer_sk:int,sr_ticket_number:int>
                  :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=103]
                  :     :        +- Filter isnotnull(s_store_sk#53)
                  :     :           +- FileScan parquet spark_catalog.tpcds.store[s_store_sk#53,s_store_name#58,s_company_id#69,s_street_number#71,s_street_name#72,s_street_type#73,s_suite_number#74,s_city#75,s_county#76,s_state#77,s_zip#78] Batched: true, DataFilters: [isnotnull(s_store_sk#53)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/angela/Desktop/spark-3.5.5-bin-hadoop3/spark-warehouse/tpc..., PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_name:string,s_company_id:int,s_street_number:string,s_street_name:s...
                  :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=107]
                  :        +- Filter isnotnull(d_date_sk#82)
                  :           +- FileScan parquet spark_catalog.tpcds.date_dim[d_date_sk#82] Batched: true, DataFilters: [isnotnull(d_date_sk#82)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/angela/Desktop/spark-3.5.5-bin-hadoop3/spark-warehouse/tpc..., PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int>
                  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=111]
                     +- Project [d_date_sk#110]
                        +- Filter ((((isnotnull(d_year#116) AND isnotnull(d_moy#118)) AND (d_year#116 = 2001)) AND (d_moy#118 = 8)) AND isnotnull(d_date_sk#110))
                           +- FileScan parquet spark_catalog.tpcds.date_dim[d_date_sk#110,d_year#116,d_moy#118] Batched: true, DataFilters: [isnotnull(d_year#116), isnotnull(d_moy#118), (d_year#116 = 2001), (d_moy#118 = 8), isnotnull(d_d..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/angela/Desktop/spark-3.5.5-bin-hadoop3/spark-warehouse/tpc..., PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2001), EqualTo(d_moy,8), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

Time taken: 2.609 seconds, Fetched 1 row(s)
